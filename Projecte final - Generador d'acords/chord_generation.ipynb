{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a52203f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "df = pd.read_csv('data/chordomicon_clean.csv')\n",
    "\n",
    "# Hiperparàmetres\n",
    "embedding_dim = 64\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "learning_rate = 1e-5\n",
    "num_epochs = 10\n",
    "batch_size = 16\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33e9c896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Definició del dataset ---\n",
    "class ChordDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = self._preprocess(data)\n",
    "        self.chord_vocab = self._build_vocab(self.data['chords_tokenized'])\n",
    "        self.section_vocab = sorted(list(set(self.data['sections'])))\n",
    "        self.genre_vocab = sorted(list(set(self.data['genres']))) \n",
    "        self.chord_to_index = {chord: idx for idx, chord in enumerate(self.chord_vocab)}\n",
    "        self.section_to_index = {section: idx for idx, section in enumerate(self.section_vocab)}\n",
    "        self.genre_to_index = {genre: idx for idx, genre in enumerate(self.genre_vocab)}\n",
    "        self.index_to_chord = {idx: chord for chord, idx in self.chord_to_index.items()}\n",
    "\n",
    "    def _preprocess(self, df):\n",
    "        sections = []\n",
    "        chords_tokenized = []\n",
    "        genres = []\n",
    "        for index, row in df.iterrows():\n",
    "            chords_str = row['chords']\n",
    "            main_genre = row['main_genre']\n",
    "            # print(f\"\\nProcesando chords_str: '{chords_str}'\")\n",
    "            split_chords = chords_str.split('<')\n",
    "            # print(f\"Resultado de split('<'): {split_chords}\")\n",
    "            for item in split_chords:\n",
    "                if '>' in item:\n",
    "                    section_label, chord_sequence = item.split('>', 1)\n",
    "                    cleaned_label = section_label.strip()\n",
    "                    sections.append(cleaned_label)\n",
    "                    chords_tokenized.append([chord.strip() for chord in chord_sequence.strip().split()])\n",
    "                    genres.append(main_genre)\n",
    "                    # print(f\"  - Item: '{item}', Etiqueta extraída: '{cleaned_label}'\")\n",
    "        return {'sections': sections, 'chords_tokenized': chords_tokenized, 'genres': genres}\n",
    "\n",
    "    def _build_vocab(self, token_lists):\n",
    "        tokens = []\n",
    "        for token_list in token_lists:\n",
    "            tokens.extend(token_list)\n",
    "        return sorted(list(set(tokens)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['sections'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        section = self.data['sections'][idx]\n",
    "        chords = self.data['chords_tokenized'][idx]\n",
    "        genre = self.data['genres'][idx]\n",
    "\n",
    "        # print(f\"Intentando acceder a la sección: '{section}'\")\n",
    "        if section not in self.section_to_index:\n",
    "            print(f\"¡¡¡ERROR!!! La sección '{section}' no está en self.section_to_index: {self.section_to_index.keys()}\")\n",
    "\n",
    "        section_index = self.section_to_index[section]\n",
    "        chord_indices = [self.chord_to_index[chord] for chord in chords]\n",
    "        genre_index = self.genre_to_index[genre]\n",
    "\n",
    "        return {\n",
    "            'section': torch.tensor(section_index, dtype=torch.long),\n",
    "            'chords': torch.tensor(chord_indices[:-1], dtype=torch.long),\n",
    "            'next_chord': torch.tensor(chord_indices[1:], dtype=torch.long),\n",
    "            'genre': torch.tensor(genre_index, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71969ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(batch):\n",
    "    sections = [item['section'] for item in batch]\n",
    "    genres = [item['genre'] for item in batch]\n",
    "    chords = [item['chords'] for item in batch]\n",
    "    next_chords = [item['next_chord'] for item in batch]\n",
    "\n",
    "    chords_padded = torch.nn.utils.rnn.pad_sequence(chords, batch_first=True)\n",
    "    next_chords_padded = torch.nn.utils.rnn.pad_sequence(next_chords, batch_first=True)\n",
    "\n",
    "    return {\n",
    "        'section': torch.stack(sections),\n",
    "        'chords': chords_padded,\n",
    "        'next_chord': next_chords_padded,\n",
    "        'genre': torch.stack(genres)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "192baaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(df, batch_size=32, shuffle=True):\n",
    "    dataset = ChordDataset(df)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=pad_sequences)\n",
    "    return dataloader, dataset.chord_vocab, dataset.section_vocab, dataset.genre_vocab, dataset.index_to_chord\n",
    "\n",
    "dataloader, chord_vocab, section_vocab, genre_vocab, index_to_chord = create_dataloader(df, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "713a7132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Definició del model ---\n",
    "class ChordGenerator(nn.Module):\n",
    "    def __init__(self, chord_vocab_size, section_vocab_size, genre_vocab_size, embedding_dim, hidden_dim, num_layers):\n",
    "        super(ChordGenerator, self).__init__()\n",
    "        self.chord_embedding = nn.Embedding(chord_vocab_size, embedding_dim)\n",
    "        self.section_embedding = nn.Embedding(section_vocab_size, embedding_dim)\n",
    "        self.genre_embedding = nn.Embedding(genre_vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim * 3, hidden_dim, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, chord_vocab_size)\n",
    "\n",
    "    def forward(self, chords, section, genre):\n",
    "        chord_embedded = self.chord_embedding(chords)\n",
    "        section_embedded = self.section_embedding(section).unsqueeze(1).expand(-1, chords.size(1), -1)\n",
    "        genre_embedded = self.genre_embedding(genre).unsqueeze(1).expand(-1, chords.size(1), -1)\n",
    "        embedded = torch.cat((chord_embedded, section_embedded, genre_embedded), dim=2)\n",
    "        output, _ = self.lstm(embedded)\n",
    "        prediction = self.linear(output)\n",
    "        return prediction\n",
    "model = ChordGenerator(len(chord_vocab), len(section_vocab), len(genre_vocab), embedding_dim, hidden_dim, num_layers)\n",
    "model.load_state_dict(torch.load(\"chord_generator2.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "895b5400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.7670\n",
      "Epoch [2/10], Loss: 0.6276\n",
      "Epoch [3/10], Loss: 0.5993\n",
      "Epoch [4/10], Loss: 0.5813\n",
      "Epoch [5/10], Loss: 0.5690\n",
      "Epoch [6/10], Loss: 0.5583\n",
      "Epoch [7/10], Loss: 0.5517\n",
      "Epoch [8/10], Loss: 0.5453\n",
      "Epoch [9/10], Loss: 0.5408\n",
      "Epoch [10/10], Loss: 0.5371\n"
     ]
    }
   ],
   "source": [
    "# --- Train loop ---\n",
    "def train(model, dataloader, learning_rate, num_epochs, device):\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            chords = batch['chords'].to(device)\n",
    "            next_chords = batch['next_chord'].to(device)\n",
    "            sections = batch['section'].to(device)\n",
    "            genres = batch['genre'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(chords, sections, genres)\n",
    "\n",
    "            loss = criterion(outputs.view(-1, outputs.size(-1)), next_chords.view(-1))\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # Un valor de max_norm = 1.0 es un buen punto de partida\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # *** DIAGNÓSTICO TEMPORAL DE LOSS ***\n",
    "            if torch.isnan(loss).any() or torch.isinf(loss).any():\n",
    "                print(f\"ATENCIÓN: Loss se ha vuelto NaN/Inf en el batch {batch_idx}, epoch {epoch}. Interrumpiendo el entrenamiento.\")\n",
    "                # Opcional: podrías guardar el modelo aquí como 'modelo_fallido.pth' para inspeccionarlo\n",
    "                return # Detiene el entrenamiento si el loss se corrompe\n",
    "            # *** FIN DIAGNÓSTICO ***\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "        \n",
    "    if not (torch.isnan(torch.tensor(avg_loss)) or torch.isinf(torch.tensor(avg_loss))):\n",
    "            torch.save(model.state_dict(), f\"chord_generator_epoch_{epoch+1}.pth\") # Guarda un modelo por época\n",
    "            torch.save(model.state_dict(), \"chord_generator.pth\") # Sobreescribe el principal\n",
    "\n",
    "train(model, dataloader, learning_rate, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45e63ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Generació d'acords ---\n",
    "def generate_chords(model, start_sequence, section_label, genre_label, chord_to_index, section_to_index, genre_to_index, index_to_chord, max_length=50, device=\"cpu\"):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        start_indices = [chord_to_index[chord] for chord in start_sequence]\n",
    "        input_sequence = torch.tensor(start_indices, dtype=torch.long).unsqueeze(0).to(device)\n",
    "        section_index = torch.tensor([section_to_index[section_label]], dtype=torch.long).to(device)\n",
    "        genre_index = torch.tensor([genre_to_index[genre_label]], dtype=torch.long).to(device)\n",
    "\n",
    "        generated_sequence = start_indices[:]\n",
    "\n",
    "        for _ in range(max_length):\n",
    "            outputs = model(input_sequence, section_index, genre_index)\n",
    "            probabilities = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "            next_chord_index = torch.multinomial(probabilities, num_samples=1).item()\n",
    "            generated_sequence.append(next_chord_index)\n",
    "            input_sequence = torch.cat((input_sequence, torch.tensor([[next_chord_index]], dtype=torch.long).to(device)), dim=1)\n",
    "\n",
    "        return [index_to_chord[idx] for idx in generated_sequence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "212d05a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generación para inicio: ['C', 'F'], sección: verse, género: pop rock\n",
      "Acordes generados: ['C', 'F', 'G', 'C']\n",
      "\n",
      "Generación para inicio: ['C'], sección: intro, género: pop\n",
      "Acordes generados para intro: ['C', 'D', 'Em', 'G', 'C', 'D', 'Em', 'G', 'C', 'D', 'Em']\n"
     ]
    }
   ],
   "source": [
    "# Exemple de generació\n",
    "start_sequence = [\"C\", \"F\"]\n",
    "section_label = \"verse\"\n",
    "genre_label = \"pop rock\"\n",
    "if start_sequence[0] not in chord_vocab or section_label not in section_vocab or genre_label not in genre_vocab:\n",
    "    print(genre_vocab)\n",
    "else:\n",
    "    generated_chords = generate_chords(\n",
    "        model, start_sequence, section_label, genre_label,\n",
    "        dataloader.dataset.chord_to_index, dataloader.dataset.section_to_index,\n",
    "        dataloader.dataset.genre_to_index, index_to_chord, device=device, max_length=2\n",
    "    )\n",
    "    print(f\"\\nGeneración para inicio: {start_sequence}, sección: {section_label}, género: {genre_label}\")\n",
    "    print(f\"Acordes generados: {generated_chords}\")\n",
    "\n",
    "# Exemple de generació per una secció diferent\n",
    "start_sequence_intro = [\"C\"]\n",
    "section_label_intro = \"intro\"\n",
    "genre_label_pop = \"pop\"\n",
    "if section_label_intro not in section_vocab or genre_label_pop not in genre_vocab:\n",
    "    print(\"Error: Uno de los tokens de entrada no está en el vocabulario.\")\n",
    "else:\n",
    "    generated_chords_intro = generate_chords(\n",
    "        model, start_sequence_intro, section_label_intro, genre_label_pop,\n",
    "        dataloader.dataset.chord_to_index, dataloader.dataset.section_to_index,\n",
    "        dataloader.dataset.genre_to_index, index_to_chord, device=device, max_length=10\n",
    "    )\n",
    "    print(f\"\\nGeneración para inicio: {start_sequence_intro}, sección: {section_label_intro}, género: {genre_label_pop}\")\n",
    "    print(f\"Acordes generados para intro: {generated_chords_intro}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex-basics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
