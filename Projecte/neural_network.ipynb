{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9ca4659",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb947edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46169b3",
   "metadata": {},
   "source": [
    "ConfiguraciÃ³ global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e7208b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- CONFIG ----------\n",
    "JSON_PATH = \"data/simplified_chords.json\"\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.001\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd99a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- LOAD DATA ----------\n",
    "with open(JSON_PATH, \"r\") as f:\n",
    "    nested_data = json.load(f)\n",
    "\n",
    "raw_data = {}\n",
    "for artist, songs in nested_data.items():\n",
    "    for song_name, chord_list in songs.items():\n",
    "        raw_data[song_name] = chord_list\n",
    "        \n",
    "all_chords = [ch for song in raw_data.values() for ch in song]\n",
    "unique_chords = sorted(set(all_chords))\n",
    "chord2idx = {ch: i for i, ch in enumerate(unique_chords)}\n",
    "idx2chord = {i: ch for ch, i in chord2idx.items()}\n",
    "\n",
    "\n",
    "def split_structure_fixed(seq):\n",
    "    unique = []\n",
    "    for ch in seq:\n",
    "        if ch not in unique:\n",
    "            unique.append(ch)\n",
    "        if len(unique) >= 10:\n",
    "            break\n",
    "    if len(unique) < 10:\n",
    "        return None\n",
    "    verse = unique[0:4]\n",
    "    bridge = unique[4:6]\n",
    "    chorus = unique[6:10]\n",
    "    return {\n",
    "        \"verse1\": verse,\n",
    "        \"verse2\": verse,\n",
    "        \"bridge\": bridge,\n",
    "        \"chorus\": chorus\n",
    "    }\n",
    "\n",
    "\n",
    "structured_data = []\n",
    "for song in raw_data.values():\n",
    "    tokens = [chord2idx[ch] for ch in song if ch in chord2idx]\n",
    "    parts = split_structure_fixed(tokens)\n",
    "    if parts:\n",
    "        structured_data.append(parts)\n",
    "\n",
    "# ---------- DATASET ----------\n",
    "class ChordDataset(Dataset):\n",
    "    def __init__(self, structured_data):\n",
    "        self.samples = []\n",
    "        for song in structured_data:\n",
    "            full = song[\"verse1\"] + song[\"verse2\"] + song[\"bridge\"] + song[\"chorus\"]\n",
    "            for i in range(len(full) - 1):\n",
    "                self.samples.append((full[i], full[i+1]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.samples[idx]\n",
    "        return torch.tensor(x), torch.tensor(y)\n",
    "\n",
    "\n",
    "dataset = ChordDataset(structured_data)\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7f6b6c",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de13bc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- MODEL ----------\n",
    "class ChordLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        x = self.embedding(x)\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "\n",
    "\n",
    "model = ChordLSTM(len(chord2idx)).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040d9fa9",
   "metadata": {},
   "source": [
    "Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04ac321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- TRAIN ----------\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        x = x.unsqueeze(1)  # shape: (batch, seq_len=1)\n",
    "        out, _ = model(x)\n",
    "        loss = criterion(out.squeeze(), y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {total_loss:.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398285a0",
   "metadata": {},
   "source": [
    "Test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31667fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- GENERATE ----------\n",
    "def generate_structured_song(seed_chord):\n",
    "    model.load_state_dict(torch.load(\"model.pth\"))\n",
    "    model.eval()\n",
    "    chord_seq = [chord2idx[seed_chord]]\n",
    "    hidden = None\n",
    "    with torch.no_grad():\n",
    "        while len(set(chord_seq)) < 10:\n",
    "            x = torch.tensor([[chord_seq[-1]]], device=DEVICE)\n",
    "            out, hidden = model(x, hidden)\n",
    "            probs = torch.softmax(out[0, -1], dim=0)\n",
    "            next_chord = torch.multinomial(probs, 1).item()\n",
    "            if next_chord not in chord_seq:\n",
    "                chord_seq.append(next_chord)\n",
    "\n",
    "    verse = chord_seq[0:4]\n",
    "    bridge = chord_seq[4:6]\n",
    "    chorus = chord_seq[6:10]\n",
    "    full_song = verse + verse + bridge + chorus\n",
    "    return [idx2chord[i] for i in full_song]\n",
    "\n",
    "# ---------- EXAMPLE ----------\n",
    "random_seed_chord = random.choice(list(chord2idx.keys()))\n",
    "generated_song = generate_structured_song(random_seed_chord)\n",
    "\n",
    "print(\"\\nðŸŽµ Generated Song Structure ðŸŽµ\")\n",
    "print(\"Verse:\", generated_song[0:4])\n",
    "print(\"Verse:\", generated_song[4:8])\n",
    "print(\"Bridge:\", generated_song[8:10])\n",
    "print(\"Chorus:\", generated_song[10:14])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex-basics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
