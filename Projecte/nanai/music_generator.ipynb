{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91f4c59a",
   "metadata": {},
   "source": [
    "# Generador de música\n",
    "### Aquest projecte serveix per generar notes musicals seguint una estructura segons el gènere musical seleccionat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c4dee3",
   "metadata": {},
   "source": [
    "Importem els paquets necessaris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623eec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def obtener_track_id_desde_path(midi_path):\n",
    "    path = Path(midi_path)\n",
    "    return path.parent.name if len(path.parts) >= 2 else None\n",
    "\n",
    "print(obtener_track_id_desde_path(\"lmd_matched/A/A/A/TRAAAGR128F425B14B/1d9d16a9da90c090809c153754823c2b.mid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880b8fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "LMD_MATCHED_DIR = 'lmd_matched'\n",
    "MSD_METADATA_DIR = 'lastfm_train'\n",
    "\n",
    "# Géneros que te interesan\n",
    "COMMON_GENRES = {\n",
    "    'rock', 'pop', 'jazz', 'blues', 'hip hop', 'rap', 'electronic',\n",
    "    'dance', 'classical', 'metal', 'punk', 'country', 'folk',\n",
    "    'reggae', 'r&b', 'soul', 'disco', 'house', 'techno', 'funk',\n",
    "    'alternative', 'indie', 'grunge', 'trance', 'synthpop', 'electropop'\n",
    "}\n",
    "\n",
    "# Normaliza el texto del género\n",
    "def normalize_genre(genre):\n",
    "    return genre.lower().strip()\n",
    "\n",
    "# Carga los metadatos y extrae el género válido\n",
    "def extract_genre(mbid):\n",
    "    metadata_path = os.path.join(MSD_METADATA_DIR, mbid + '.json')\n",
    "    if not os.path.exists(metadata_path):\n",
    "        return None\n",
    "\n",
    "    with open(metadata_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        print(data)\n",
    "\n",
    "    tags = data.get('tags', [])\n",
    "    for tag_entry in tags:\n",
    "        if isinstance(tag_entry, list) and len(tag_entry) >= 1:\n",
    "            tag = tag_entry[0].lower().strip()\n",
    "            if tag in COMMON_GENRES:\n",
    "                return tag\n",
    "    return None\n",
    "\n",
    "# Asociación final: solo mbid, midi_path y género\n",
    "midi_with_genres = []\n",
    "\n",
    "for root, _, files in os.walk(LMD_MATCHED_DIR):\n",
    "    for file in files:\n",
    "        if file.lower().endswith('.mid') or file.lower().endswith('.midi'):\n",
    "            mbid = os.path.basename(root)\n",
    "            midi_path = os.path.join(root, file)\n",
    "            genre = extract_genre(mbid)\n",
    "\n",
    "            if genre:\n",
    "                midi_with_genres.append({\n",
    "                    'mbid': mbid,\n",
    "                    'midi_path': midi_path,\n",
    "                    'genre': genre\n",
    "                })\n",
    "\n",
    "# Guardamos el resultado\n",
    "with open('lmd_genre_filtered.json', 'w') as out_f:\n",
    "    json.dump(midi_with_genres, out_f, indent=2)\n",
    "\n",
    "print(f\"Total MIDI con género válido: {len(midi_with_genres)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bfab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "\n",
    "midi = pretty_midi.PrettyMIDI(\"Midi Dataset Clean/ARMSTRONG_LOUIS/What_a_Wonderful_World.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b00d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter, chord\n",
    "score = converter.parse(\"Midi Dataset Clean/ARMSTRONG_LOUIS/What_a_Wonderful_World.mid\")\n",
    "chords = score.chordify()\n",
    "\n",
    "print(chords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c30afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pretty_midi\n",
    "\n",
    "def extract_chords_from_midi(midi_path):\n",
    "    try:\n",
    "        midi_data = pretty_midi.PrettyMIDI(midi_path)\n",
    "        chords = set()\n",
    "\n",
    "        for instrument in midi_data.instruments:\n",
    "            if instrument.is_drum:\n",
    "                continue\n",
    "            notes = instrument.notes\n",
    "            if len(notes) < 3:\n",
    "                continue\n",
    "\n",
    "            # Agrupar por tiempo cercano para detectar acordes\n",
    "            notes.sort(key=lambda note: note.start)\n",
    "            current_chord = []\n",
    "            last_start = None\n",
    "            for note in notes:\n",
    "                if last_start is None or abs(note.start - last_start) < 0.05:\n",
    "                    current_chord.append(note.pitch)\n",
    "                    last_start = note.start\n",
    "                else:\n",
    "                    if len(current_chord) >= 3:\n",
    "                        chord = tuple(sorted(current_chord))\n",
    "                        chords.add(chord)\n",
    "                    current_chord = [note.pitch]\n",
    "                    last_start = note.start\n",
    "            if len(current_chord) >= 3:\n",
    "                chord = tuple(sorted(current_chord))\n",
    "                chords.add(chord)\n",
    "\n",
    "        return [list(chord) for chord in chords]\n",
    "    except Exception as e:\n",
    "        print(f\"Error en {midi_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Ruta al directorio raíz\n",
    "root_dir = \"Midi Dataset Clean\"\n",
    "output = {}\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    for filename in filenames:\n",
    "        if filename.lower().endswith((\".mid\", \".midi\")):\n",
    "            midi_path = os.path.join(dirpath, filename)\n",
    "            chords = extract_chords_from_midi(midi_path)\n",
    "            if chords:\n",
    "                output[os.path.relpath(midi_path, root_dir)] = chords\n",
    "\n",
    "# Guardar a un JSON\n",
    "with open(\"midi_chords.json\", \"w\") as f:\n",
    "    json.dump(output, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60957c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import chord, pitch\n",
    "\n",
    "def midi_notes_to_chord_name(notes):\n",
    "    try:\n",
    "        c = chord.Chord(notes)\n",
    "        return c.figure  # Ej: \"C\", \"Am\", \"G7\"\n",
    "    except Exception:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66b9cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"midi_chords.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "sequences = []\n",
    "for midi_path, chords in data.items():\n",
    "    sequence = []\n",
    "    for chord_notes in chords:\n",
    "        name = midi_notes_to_chord_name(chord_notes)\n",
    "        if name:\n",
    "            sequence.append(name)\n",
    "    if sequence:\n",
    "        sequences.append(sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dbee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(filters='', lower=False)\n",
    "tokenizer.fit_on_texts(sequences)\n",
    "sequences_int = tokenizer.texts_to_sequences(sequences)\n",
    "\n",
    "max_len = max(len(seq) for seq in sequences_int)\n",
    "padded_sequences = pad_sequences(sequences_int, maxlen=max_len, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa27cb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 - Loss: 67832.2207\n",
      "Epoch 2/30 - Loss: 54513.7836\n",
      "Epoch 3/30 - Loss: 46864.9474\n",
      "Epoch 4/30 - Loss: 40720.0186\n",
      "Epoch 5/30 - Loss: 35599.1704\n",
      "Epoch 6/30 - Loss: 31300.9487\n",
      "Epoch 7/30 - Loss: 27628.9948\n",
      "Epoch 8/30 - Loss: 24480.4032\n",
      "Epoch 9/30 - Loss: 21803.0740\n",
      "Epoch 10/30 - Loss: 19521.0069\n",
      "Epoch 11/30 - Loss: 17621.4202\n",
      "Epoch 12/30 - Loss: 16060.9486\n",
      "Epoch 13/30 - Loss: 14809.5517\n",
      "Epoch 14/30 - Loss: 13748.8691\n",
      "Epoch 15/30 - Loss: 12911.5473\n",
      "Epoch 16/30 - Loss: 12160.1785\n",
      "Epoch 17/30 - Loss: 11550.4486\n",
      "Epoch 18/30 - Loss: 11039.9253\n",
      "Epoch 19/30 - Loss: 10565.0929\n",
      "Epoch 20/30 - Loss: 10162.0410\n",
      "Epoch 21/30 - Loss: 9807.5783\n",
      "Epoch 22/30 - Loss: 9498.8634\n",
      "Epoch 23/30 - Loss: 9225.2211\n",
      "Epoch 24/30 - Loss: 8981.4779\n",
      "Epoch 25/30 - Loss: 8752.4094\n",
      "Epoch 26/30 - Loss: 8570.6748\n",
      "Epoch 27/30 - Loss: 8395.5724\n",
      "Epoch 28/30 - Loss: 8237.6612\n",
      "Epoch 29/30 - Loss: 8092.2417\n",
      "Epoch 30/30 - Loss: 7962.8019\n",
      "Generación completada.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# ========= CONFIG =========\n",
    "SEQ_LEN = 16\n",
    "BATCH_SIZE = 64\n",
    "HIDDEN_SIZE = 128\n",
    "EPOCHS = 30\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ========= CARGA Y PROCESADO =========\n",
    "with open(\"midi_chords.json\", \"r\") as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "# Convertimos acordes a tuplas para que sean hasheables\n",
    "all_chords = []\n",
    "for chords in raw_data.values():\n",
    "    for chord in chords:\n",
    "        chord_tuple = tuple(sorted(chord))  # ordena para normalizar\n",
    "        all_chords.append(chord_tuple)\n",
    "\n",
    "# Creamos vocabulario\n",
    "unique_chords = sorted(list(set(all_chords)))\n",
    "chord2idx = {ch: i for i, ch in enumerate(unique_chords)}\n",
    "idx2chord = {i: ch for ch, i in chord2idx.items()}\n",
    "\n",
    "# Convertimos a índices\n",
    "encoded_data = []\n",
    "for chords in raw_data.values():\n",
    "    sequence = [chord2idx[tuple(sorted(ch))] for ch in chords]\n",
    "    encoded_data.append(sequence)\n",
    "\n",
    "# Construimos pares input-output\n",
    "inputs, targets = [], []\n",
    "for seq in encoded_data:\n",
    "    for i in range(len(seq) - SEQ_LEN):\n",
    "        inputs.append(seq[i:i+SEQ_LEN])\n",
    "        targets.append(seq[i+SEQ_LEN])\n",
    "\n",
    "# ========= DATASET =========\n",
    "class ChordDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.tensor(x, dtype=torch.long)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "dataset = ChordDataset(inputs, targets)\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# ========= MODELO =========\n",
    "class ChordRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        output, _ = self.lstm(x)\n",
    "        output = self.fc(output[:, -1])\n",
    "        return output\n",
    "\n",
    "model = ChordRNN(len(chord2idx), HIDDEN_SIZE).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# ========= ENTRENAMIENTO =========\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for x_batch, y_batch in loader:\n",
    "        x_batch, y_batch = x_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_batch)\n",
    "        loss = loss_fn(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {total_loss:.4f}\")\n",
    "\n",
    "# ========= GENERACIÓN =========\n",
    "def generate_sequence(start_seq, length):\n",
    "    model.eval()\n",
    "    result = start_seq[:]\n",
    "    input_seq = torch.tensor(start_seq, dtype=torch.long).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    for _ in range(length):\n",
    "        if input_seq.size(1) < SEQ_LEN:\n",
    "            padded = torch.zeros((1, SEQ_LEN), dtype=torch.long).to(DEVICE)\n",
    "            padded[0, -input_seq.size(1):] = input_seq\n",
    "            input_seq = padded\n",
    "\n",
    "        pred = model(input_seq[:, -SEQ_LEN:])\n",
    "        next_idx = torch.argmax(pred, dim=1).item()\n",
    "        result.append(next_idx)\n",
    "        input_seq = torch.tensor(result[-SEQ_LEN:], dtype=torch.long).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    return [idx2chord[i] for i in result]\n",
    "\n",
    "# ========= GENERAR CON ESTRUCTURA =========\n",
    "structure = {\n",
    "    \"estrofa\": 8,\n",
    "    \"puente\": 4,\n",
    "    \"estribillo\": 8\n",
    "}\n",
    "\n",
    "order = [\"estrofa\", \"estrofa\", \"puente\", \"estribillo\", \"estrofa\", \"estrofa\", \"puente\", \"estribillo\"]\n",
    "\n",
    "start = random.choice(inputs)\n",
    "generated = []\n",
    "\n",
    "for part in order:\n",
    "    length = structure[part]\n",
    "    gen_part = generate_sequence(start[-SEQ_LEN:], length)\n",
    "    generated.extend(gen_part)\n",
    "    start = [chord2idx[tuple(ch)] for ch in gen_part]\n",
    "\n",
    "# ========= GUARDAR =========\n",
    "with open(\"acordes_generados.json\", \"w\") as f:\n",
    "    json.dump([list(ch) for ch in generated], f, indent=2)\n",
    "\n",
    "print(\"Generación completada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14b82db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184 acordes extraídos.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Cargar el archivo JSON con secuencias de notas\n",
    "with open(\"acordes_generados.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convertimos a acordes válidos\n",
    "chord_sequence = []\n",
    "\n",
    "for notes in data:\n",
    "    # Eliminamos repeticiones y ordenamos\n",
    "    unique_notes = sorted(list(set(notes)))\n",
    "    \n",
    "    # Consideramos solo como acordes los que tengan al menos 2 notas\n",
    "    if len(unique_notes) >= 2:\n",
    "        chord_sequence.append(unique_notes)\n",
    "\n",
    "# Guardamos el resultado\n",
    "with open(\"acordes_filtrados.json\", \"w\") as f:\n",
    "    json.dump(chord_sequence, f, indent=2)\n",
    "\n",
    "print(f\"{len(chord_sequence)} acordes extraídos.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex-basics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
