{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90a6509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ====================\n",
    "# 1. PREPROCESAMIENTO\n",
    "# ====================\n",
    "def clean_chord_progression(progression):\n",
    "    \"\"\"Normaliza acordes y estructura\"\"\"\n",
    "    # Normalizar formato de acordes\n",
    "    progression = re.sub(r'min', 'm', progression, flags=re.IGNORECASE)\n",
    "    progression = re.sub(r'sus|dim|aug', '', progression)  # Elimina extensiones avanzadas\n",
    "    progression = re.sub(r'([A-G])s', r'\\1#', progression)  # Fsm -> F#m\n",
    "    \n",
    "    # Normalizar estructura\n",
    "    progression = re.sub(r'(<[a-z]+)_\\d+>', r'\\1>', progression)  # <verse_1> -> <verse>\n",
    "    return progression\n",
    "\n",
    "def preprocess_data(filepath):\n",
    "    \"\"\"Carga y limpia el dataset\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Limpieza básica\n",
    "    df = df[df['chords'].notna() & df['main_genre'].notna()].copy()\n",
    "    df['chords'] = df['chords'].apply(clean_chord_progression)\n",
    "    \n",
    "    # Extraer etiquetas de estructura\n",
    "    def extract_structure(chord_sequence):\n",
    "        tags = list(set(re.findall(r'<([a-z]+)>', chord_sequence)))\n",
    "        return ' '.join(sorted(tags)) if tags else 'verse'  # Default si no hay tags\n",
    "    \n",
    "    df['structure'] = df['chords'].apply(extract_structure)\n",
    "    \n",
    "    # Crear todas las combinaciones posibles\n",
    "    all_structures = set()\n",
    "    for s in df['structure']:\n",
    "        parts = s.split()\n",
    "        all_structures.add(s)\n",
    "        # Añadir sub-combinaciones\n",
    "        for i in range(1, len(parts)):\n",
    "            all_structures.add(' '.join(parts[:i]))\n",
    "    \n",
    "    # Añadir estructuras comunes manualmente\n",
    "    common_structures = [\n",
    "        'intro verse chorus',\n",
    "        'verse chorus',\n",
    "        'intro verse bridge chorus',\n",
    "        'verse prechorus chorus'\n",
    "    ]\n",
    "    all_structures.update(common_structures)\n",
    "    \n",
    "    # Codificadores\n",
    "    genre_encoder = LabelEncoder()\n",
    "    df['genre_id'] = genre_encoder.fit_transform(df['main_genre'])\n",
    "    \n",
    "    structure_encoder = LabelEncoder()\n",
    "    structure_encoder.fit(list(all_structures))\n",
    "    \n",
    "    # Manejar casos vacíos o desconocidos\n",
    "    df['structure'] = df['structure'].apply(\n",
    "        lambda x: x if x in all_structures else 'verse chorus'\n",
    "    )\n",
    "    df['structure_id'] = structure_encoder.transform(df['structure'])\n",
    "    \n",
    "    return df, genre_encoder, structure_encoder\n",
    "\n",
    "# ====================\n",
    "# 2. DATASET & MODELO\n",
    "# ====================\n",
    "class ChordDataset(Dataset):\n",
    "    def __init__(self, df, chord_to_idx, seq_length=32):\n",
    "        self.seq_length = seq_length\n",
    "        self.sequences = []\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            chords = [chord_to_idx.get(c, 1) for c in row['chords'].split()]  # 1 = <unk>\n",
    "            for i in range(0, len(chords) - seq_length, seq_length//2):\n",
    "                self.sequences.append({\n",
    "                    'input': chords[i:i+seq_length],\n",
    "                    'target': chords[i+1:i+seq_length+1],\n",
    "                    'genre': row['genre_id'],\n",
    "                    'structure': row['structure_id']\n",
    "                })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        return {\n",
    "            'input': torch.tensor(seq['input'], dtype=torch.long),\n",
    "            'target': torch.tensor(seq['target'], dtype=torch.long),\n",
    "            'genre': torch.tensor(seq['genre'], dtype=torch.long),\n",
    "            'structure': torch.tensor(seq['structure'], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "class ChordTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, num_genres, num_structures, d_model=128, nhead=4, num_layers=4):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Embeddings con dimensiones ajustadas\n",
    "        self.chord_embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.genre_embed = nn.Embedding(num_genres, d_model//4)  # 32-dim\n",
    "        self.structure_embed = nn.Embedding(num_structures, d_model//4)  # 32-dim\n",
    "        \n",
    "        # Capa de proyección para unificar dimensiones\n",
    "        self.combine = nn.Linear(d_model + d_model//2, d_model)  # 128 + 64 = 192 -> 128\n",
    "        \n",
    "        # Transformer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=d_model*4,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        \n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "        \n",
    "    def forward(self, x, genre, structure):\n",
    "        # Embeddings\n",
    "        chord_emb = self.chord_embed(x)  # (batch, seq_len, 128)\n",
    "        genre_emb = self.genre_embed(genre).unsqueeze(1).expand(-1, x.size(1), -1)  # (batch, seq_len, 32)\n",
    "        structure_emb = self.structure_embed(structure).unsqueeze(1).expand(-1, x.size(1), -1)  # (batch, seq_len, 32)\n",
    "        \n",
    "        # Combinar y proyectar\n",
    "        combined = torch.cat([chord_emb, genre_emb, structure_emb], dim=-1)  # (batch, seq_len, 192)\n",
    "        x = self.combine(combined)  # (batch, seq_len, 128)\n",
    "        \n",
    "        # Transformer\n",
    "        x = self.transformer(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "# ====================\n",
    "# 3. ENTRENAMIENTO\n",
    "# ====================\n",
    "def train_model(model, dataloader, val_loader=None, epochs=20):\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignora <pad>\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=3e-4)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, \n",
    "        max_lr=3e-4,\n",
    "        steps_per_epoch=len(dataloader),\n",
    "        epochs=epochs\n",
    "    )\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}\"):\n",
    "            inputs = batch['input'].to(device)\n",
    "            targets = batch['target'].to(device)\n",
    "            genres = batch['genre'].to(device)\n",
    "            structures = batch['structure'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs, genres, structures)\n",
    "            loss = criterion(\n",
    "                outputs.view(-1, outputs.size(-1)), \n",
    "                targets.view(-1)\n",
    "            )\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validación\n",
    "        if val_loader:\n",
    "            val_loss = evaluate(model, val_loader, criterion)\n",
    "            print(f\"Epoch {epoch+1} | Train Loss: {train_loss/len(dataloader):.4f} | Val Loss: {val_loss:.4f}\")\n",
    "        else:\n",
    "            print(f\"Epoch {epoch+1} | Train Loss: {train_loss/len(dataloader):.4f}\")\n",
    "            \n",
    "    torch.save(model.state_dict(), \"model_final2.pth\")\n",
    "\n",
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs = batch['input'].to(device)\n",
    "            targets = batch['target'].to(device)\n",
    "            genres = batch['genre'].to(device)\n",
    "            structures = batch['structure'].to(device)\n",
    "            \n",
    "            outputs = model(inputs, genres, structures)\n",
    "            loss = criterion(\n",
    "                outputs.view(-1, outputs.size(-1)), \n",
    "                targets.view(-1)\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# ====================\n",
    "# 4. GENERACIÓN\n",
    "# ====================\n",
    "\n",
    "# ====================\n",
    "# 5. EJECUCIÓN\n",
    "# ====================\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuración\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    # 1. Preprocesamiento\n",
    "    print(\"Preprocesando datos...\")\n",
    "    df, genre_encoder, structure_encoder = preprocess_data(\"data/chordomicon_clean.csv\")\n",
    "    \n",
    "    # 2. Vocabulario\n",
    "    all_chords = list(set([c for s in df['chords'] for c in s.split()]))\n",
    "    vocab = ['<pad>', '<unk>'] + sorted(all_chords)\n",
    "    vocab_size = len(vocab)\n",
    "    chord_to_idx = {v: i for i, v in enumerate(vocab)}\n",
    "    idx_to_chord = {i: v for i, v in enumerate(vocab)}\n",
    "    \n",
    "    # 3. Datasets\n",
    "    print(\"Creando datasets...\")\n",
    "    train_df = df.sample(frac=0.8)\n",
    "    val_df = df.drop(train_df.index)\n",
    "    \n",
    "    train_dataset = ChordDataset(train_df, chord_to_idx)\n",
    "    val_dataset = ChordDataset(val_df, chord_to_idx)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "    \n",
    "    # 4. Modelo\n",
    "    print(\"Inicializando modelo...\")\n",
    "    model = ChordTransformer(\n",
    "        vocab_size=vocab_size,\n",
    "        num_genres=len(genre_encoder.classes_),\n",
    "        num_structures=len(structure_encoder.classes_)\n",
    "    ).to(device)\n",
    "    \n",
    "    # 5. Entrenamiento\n",
    "    print(\"Comenzando entrenamiento...\")\n",
    "    train_model(model, train_loader, val_loader, epochs=20)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea71353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chords(model, genre, structure, start_seq=\"<intro> <verse> <chorus>\", max_len=32, temperature=0.7):\n",
    "    model.eval()\n",
    "    \n",
    "    # Validar y formatear estructura\n",
    "    if not isinstance(structure, str) or not structure.strip():\n",
    "        structure = \"verse chorus\"\n",
    "    \n",
    "    structure_parts = [s for s in structure.split() if s]\n",
    "    formatted_structure = ' '.join(\n",
    "        f'<{p}>' if not p.startswith('<') else p \n",
    "        for p in structure_parts\n",
    "    )\n",
    "    \n",
    "    # Codificar con manejo de errores\n",
    "    try:\n",
    "        structure_id = structure_encoder.transform([formatted_structure])[0]\n",
    "    except ValueError:\n",
    "        known_structures = structure_encoder.classes_\n",
    "        fallback = 'verse chorus' if 'verse chorus' in known_structures else known_structures[0]\n",
    "        print(f\"Estructura '{structure}' no válida. Usando '{fallback}'\")\n",
    "        structure_id = structure_encoder.transform([fallback])[0]\n",
    "    \n",
    "    # Resto de la generación...\n",
    "    genre_id = torch.tensor([genre_encoder.transform([genre])[0]], device=device)\n",
    "    input_seq = [chord_to_idx.get(s, 1) for s in start_seq.split() if s]\n",
    "    \n",
    "    if not input_seq:  # Si start_seq está vacío\n",
    "        input_seq = [chord_to_idx.get('<intro>', 1)]\n",
    "        \n",
    "    input_tensor = torch.tensor([input_seq], dtype=torch.long, device=device)\n",
    "    generated = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_len):\n",
    "            output = model(input_tensor, genre_id, torch.tensor([structure_id], device=device))\n",
    "            probs = torch.softmax(output[0, -1] / temperature, dim=-1)\n",
    "            next_idx = torch.multinomial(probs, 1).item()\n",
    "            next_chord = idx_to_chord[next_idx]\n",
    "            \n",
    "            generated.append(next_chord)\n",
    "            input_tensor = torch.cat([input_tensor, torch.tensor([[next_idx]], device=device)], dim=1)\n",
    "            \n",
    "            if next_chord.startswith('<') and len(generated) > 5:\n",
    "                break\n",
    "    \n",
    "    return ' '.join(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "012d739d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estructura 'intro verse chorus' no válida. Usando 'verse chorus'\n",
      "<intro> <intro> <intro> <intro> <intro> <intro>\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo con estructura compleja\n",
    "progresion = generate_chords(\n",
    "    model=model,\n",
    "    genre=\"rock\",\n",
    "    structure=\"intro verse chorus\",  # Combinación no vista en entrenamiento\n",
    "    start_seq=\"\"\n",
    ")\n",
    "print(progresion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90aadf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estructuras disponibles:\n",
      "0: bridge\n",
      "1: bridge chorus\n",
      "2: bridge chorus instrumental\n",
      "3: bridge chorus instrumental interlude\n",
      "4: bridge chorus instrumental interlude intro\n",
      "5: bridge chorus instrumental interlude intro outro\n",
      "6: bridge chorus instrumental interlude intro outro solo\n",
      "7: bridge chorus instrumental interlude intro outro solo verse\n",
      "8: bridge chorus instrumental interlude intro outro verse\n",
      "9: bridge chorus instrumental interlude intro solo\n",
      "10: bridge chorus instrumental interlude intro solo verse\n",
      "11: bridge chorus instrumental interlude intro verse\n",
      "12: bridge chorus instrumental interlude outro\n",
      "13: bridge chorus instrumental interlude outro solo\n",
      "14: bridge chorus instrumental interlude outro solo verse\n",
      "15: bridge chorus instrumental interlude outro verse\n",
      "16: bridge chorus instrumental interlude solo\n",
      "17: bridge chorus instrumental interlude solo verse\n",
      "18: bridge chorus instrumental interlude verse\n",
      "19: bridge chorus instrumental intro\n",
      "20: bridge chorus instrumental intro outro\n",
      "21: bridge chorus instrumental intro outro solo\n",
      "22: bridge chorus instrumental intro outro solo verse\n",
      "23: bridge chorus instrumental intro outro verse\n",
      "24: bridge chorus instrumental intro solo\n",
      "25: bridge chorus instrumental intro solo verse\n",
      "26: bridge chorus instrumental intro verse\n",
      "27: bridge chorus instrumental outro\n",
      "28: bridge chorus instrumental outro solo\n",
      "29: bridge chorus instrumental outro solo verse\n",
      "30: bridge chorus instrumental outro verse\n",
      "31: bridge chorus instrumental solo\n",
      "32: bridge chorus instrumental solo verse\n",
      "33: bridge chorus instrumental verse\n",
      "34: bridge chorus interlude\n",
      "35: bridge chorus interlude intro\n",
      "36: bridge chorus interlude intro outro\n",
      "37: bridge chorus interlude intro outro solo\n",
      "38: bridge chorus interlude intro outro solo verse\n",
      "39: bridge chorus interlude intro outro verse\n",
      "40: bridge chorus interlude intro solo\n",
      "41: bridge chorus interlude intro solo verse\n",
      "42: bridge chorus interlude intro verse\n",
      "43: bridge chorus interlude outro\n",
      "44: bridge chorus interlude outro solo\n",
      "45: bridge chorus interlude outro solo verse\n",
      "46: bridge chorus interlude outro verse\n",
      "47: bridge chorus interlude solo\n",
      "48: bridge chorus interlude solo verse\n",
      "49: bridge chorus interlude verse\n",
      "50: bridge chorus intro\n",
      "51: bridge chorus intro outro\n",
      "52: bridge chorus intro outro solo\n",
      "53: bridge chorus intro outro solo verse\n",
      "54: bridge chorus intro outro verse\n",
      "55: bridge chorus intro solo\n",
      "56: bridge chorus intro solo verse\n",
      "57: bridge chorus intro verse\n",
      "58: bridge chorus outro\n",
      "59: bridge chorus outro solo\n",
      "60: bridge chorus outro solo verse\n",
      "61: bridge chorus outro verse\n",
      "62: bridge chorus solo\n",
      "63: bridge chorus solo verse\n",
      "64: bridge chorus verse\n",
      "65: bridge instrumental\n",
      "66: bridge instrumental interlude\n",
      "67: bridge instrumental interlude intro\n",
      "68: bridge instrumental interlude intro outro\n",
      "69: bridge instrumental interlude intro outro solo\n",
      "70: bridge instrumental interlude intro outro solo verse\n",
      "71: bridge instrumental interlude intro outro verse\n",
      "72: bridge instrumental interlude intro verse\n",
      "73: bridge instrumental interlude outro\n",
      "74: bridge instrumental interlude outro verse\n",
      "75: bridge instrumental interlude verse\n",
      "76: bridge instrumental intro\n",
      "77: bridge instrumental intro outro\n",
      "78: bridge instrumental intro outro solo\n",
      "79: bridge instrumental intro outro solo verse\n",
      "80: bridge instrumental intro outro verse\n",
      "81: bridge instrumental intro solo\n",
      "82: bridge instrumental intro solo verse\n",
      "83: bridge instrumental intro verse\n",
      "84: bridge instrumental outro\n",
      "85: bridge instrumental outro solo\n",
      "86: bridge instrumental outro solo verse\n",
      "87: bridge instrumental outro verse\n",
      "88: bridge instrumental solo\n",
      "89: bridge instrumental verse\n",
      "90: bridge interlude\n",
      "91: bridge interlude intro\n",
      "92: bridge interlude intro outro\n",
      "93: bridge interlude intro outro solo\n",
      "94: bridge interlude intro outro solo verse\n",
      "95: bridge interlude intro outro verse\n",
      "96: bridge interlude intro solo\n",
      "97: bridge interlude intro solo verse\n",
      "98: bridge interlude intro verse\n",
      "99: bridge interlude outro\n",
      "100: bridge interlude outro solo\n",
      "101: bridge interlude outro solo verse\n",
      "102: bridge interlude outro verse\n",
      "103: bridge interlude solo\n",
      "104: bridge interlude solo verse\n",
      "105: bridge interlude verse\n",
      "106: bridge intro\n",
      "107: bridge intro outro\n",
      "108: bridge intro outro solo\n",
      "109: bridge intro outro solo verse\n",
      "110: bridge intro outro verse\n",
      "111: bridge intro solo\n",
      "112: bridge intro solo verse\n",
      "113: bridge intro verse\n",
      "114: bridge outro\n",
      "115: bridge outro solo\n",
      "116: bridge outro solo verse\n",
      "117: bridge outro verse\n",
      "118: bridge solo\n",
      "119: bridge solo verse\n",
      "120: bridge verse\n",
      "121: chorus\n",
      "122: chorus instrumental\n",
      "123: chorus instrumental interlude\n",
      "124: chorus instrumental interlude intro\n",
      "125: chorus instrumental interlude intro outro\n",
      "126: chorus instrumental interlude intro outro solo\n",
      "127: chorus instrumental interlude intro outro solo verse\n",
      "128: chorus instrumental interlude intro outro verse\n",
      "129: chorus instrumental interlude intro solo\n",
      "130: chorus instrumental interlude intro solo verse\n",
      "131: chorus instrumental interlude intro verse\n",
      "132: chorus instrumental interlude outro\n",
      "133: chorus instrumental interlude outro solo\n",
      "134: chorus instrumental interlude outro solo verse\n",
      "135: chorus instrumental interlude outro verse\n",
      "136: chorus instrumental interlude solo\n",
      "137: chorus instrumental interlude solo verse\n",
      "138: chorus instrumental interlude verse\n",
      "139: chorus instrumental intro\n",
      "140: chorus instrumental intro outro\n",
      "141: chorus instrumental intro outro solo\n",
      "142: chorus instrumental intro outro solo verse\n",
      "143: chorus instrumental intro outro verse\n",
      "144: chorus instrumental intro solo\n",
      "145: chorus instrumental intro solo verse\n",
      "146: chorus instrumental intro verse\n",
      "147: chorus instrumental outro\n",
      "148: chorus instrumental outro solo\n",
      "149: chorus instrumental outro solo verse\n",
      "150: chorus instrumental outro verse\n",
      "151: chorus instrumental solo\n",
      "152: chorus instrumental solo verse\n",
      "153: chorus instrumental verse\n",
      "154: chorus interlude\n",
      "155: chorus interlude intro\n",
      "156: chorus interlude intro outro\n",
      "157: chorus interlude intro outro solo\n",
      "158: chorus interlude intro outro solo verse\n",
      "159: chorus interlude intro outro verse\n",
      "160: chorus interlude intro solo\n",
      "161: chorus interlude intro solo verse\n",
      "162: chorus interlude intro verse\n",
      "163: chorus interlude outro\n",
      "164: chorus interlude outro solo\n",
      "165: chorus interlude outro solo verse\n",
      "166: chorus interlude outro verse\n",
      "167: chorus interlude solo\n",
      "168: chorus interlude solo verse\n",
      "169: chorus interlude verse\n",
      "170: chorus intro\n",
      "171: chorus intro outro\n",
      "172: chorus intro outro solo\n",
      "173: chorus intro outro solo verse\n",
      "174: chorus intro outro verse\n",
      "175: chorus intro solo\n",
      "176: chorus intro solo verse\n",
      "177: chorus intro verse\n",
      "178: chorus outro\n",
      "179: chorus outro solo\n",
      "180: chorus outro solo verse\n",
      "181: chorus outro verse\n",
      "182: chorus solo\n",
      "183: chorus solo verse\n",
      "184: chorus verse\n",
      "185: instrumental\n",
      "186: instrumental interlude\n",
      "187: instrumental interlude intro\n",
      "188: instrumental interlude intro outro\n",
      "189: instrumental interlude intro outro solo\n",
      "190: instrumental interlude intro outro solo verse\n",
      "191: instrumental interlude intro outro verse\n",
      "192: instrumental interlude intro solo\n",
      "193: instrumental interlude intro solo verse\n",
      "194: instrumental interlude intro verse\n",
      "195: instrumental interlude outro\n",
      "196: instrumental interlude outro verse\n",
      "197: instrumental interlude verse\n",
      "198: instrumental intro\n",
      "199: instrumental intro outro\n",
      "200: instrumental intro outro solo\n",
      "201: instrumental intro outro solo verse\n",
      "202: instrumental intro outro verse\n",
      "203: instrumental intro solo\n",
      "204: instrumental intro solo verse\n",
      "205: instrumental intro verse\n",
      "206: instrumental outro\n",
      "207: instrumental outro solo\n",
      "208: instrumental outro solo verse\n",
      "209: instrumental outro verse\n",
      "210: instrumental solo\n",
      "211: instrumental solo verse\n",
      "212: instrumental verse\n",
      "213: interlude\n",
      "214: interlude intro\n",
      "215: interlude intro outro\n",
      "216: interlude intro outro solo\n",
      "217: interlude intro outro solo verse\n",
      "218: interlude intro outro verse\n",
      "219: interlude intro solo\n",
      "220: interlude intro solo verse\n",
      "221: interlude intro verse\n",
      "222: interlude outro\n",
      "223: interlude outro solo\n",
      "224: interlude outro solo verse\n",
      "225: interlude outro verse\n",
      "226: interlude solo\n",
      "227: interlude solo verse\n",
      "228: interlude verse\n",
      "229: intro\n",
      "230: intro outro\n",
      "231: intro outro solo\n",
      "232: intro outro solo verse\n",
      "233: intro outro verse\n",
      "234: intro solo\n",
      "235: intro solo verse\n",
      "236: intro verse\n",
      "237: intro verse bridge chorus\n",
      "238: intro verse chorus\n",
      "239: outro\n",
      "240: outro solo\n",
      "241: outro solo verse\n",
      "242: outro verse\n",
      "243: solo\n",
      "244: solo verse\n",
      "245: verse\n",
      "246: verse chorus\n",
      "247: verse prechorus chorus\n"
     ]
    }
   ],
   "source": [
    "# Después de entrenar el modelo y crear el structure_encoder\n",
    "print(\"Estructuras disponibles:\")\n",
    "for i, structure in enumerate(structure_encoder.classes_):\n",
    "    print(f\"{i}: {structure}\")\n",
    "\n",
    "# También puedes obtenerlas como lista\n",
    "estructuras_disponibles = list(structure_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f78e8566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   chords   main_genre  \\\n",
      "0       <intro> E D A E D A <verse> E D A E D A E D A ...        metal   \n",
      "1       <intro> C <verse> G C G C <chorus> F Dm G Dm G...          pop   \n",
      "2       <intro> G Bm Am D G Bm <verse> Am D G Em Am D ...          pop   \n",
      "3       <intro> F#m F B E F B E F#m B <chorus> A G#m B...          pop   \n",
      "4       <chorus> C Am Dm G C G Am Dm G C <verse> Dm C ...          pop   \n",
      "...                                                   ...          ...   \n",
      "277919  B C F E B E B F E B F E B E B E B D#m E B F E ...         punk   \n",
      "277920  A D E A D E A D E A D E A D E A D E A D E A D ...  alternative   \n",
      "277921  C G Am F C G Am F C Am G Am F Fm C Am C Am F F...          pop   \n",
      "277922  D#m C#m A#m D#m C# A#m G C#m Fm D# Fm C#m Fm D...         rock   \n",
      "277923  Dm A# C Dm A# C Dm A# C Dm F G# C# F# Dm Gm C ...         punk   \n",
      "\n",
      "                        structure  genre_id  structure_id  \n",
      "0       bridge chorus intro verse         4            57  \n",
      "1              chorus intro verse         5           177  \n",
      "2        chorus intro outro verse         5           174  \n",
      "3              chorus intro outro         5           171  \n",
      "4              chorus outro verse         5           181  \n",
      "...                           ...       ...           ...  \n",
      "277919                      verse         7           245  \n",
      "277920                      verse         0           245  \n",
      "277921                      verse         5           245  \n",
      "277922                      verse        10           245  \n",
      "277923                      verse         7           245  \n",
      "\n",
      "[277924 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df.iloc[1:].reset_index(drop=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c403888e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m---> 29\u001b[0m     loss \u001b[38;5;241m=\u001b[39m train_epoch(model, \u001b[43mdataloader\u001b[49m)\n\u001b[1;32m     30\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "# 5. Entrenamiento\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.8)\n",
    "\n",
    "def train_epoch(model, dataloader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(tqdm(dataloader)):\n",
    "        inputs = batch['input'].to(device)\n",
    "        targets = batch['target'].to(device)\n",
    "        genres = batch['genre'].to(device)\n",
    "        structures = batch['structure'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, genres, structures)\n",
    "        \n",
    "        loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "for epoch in range(10):\n",
    "    loss = train_epoch(model, dataloader)\n",
    "    scheduler.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss:.4f}')\n",
    "\n",
    "torch.save(model.state_dict(), \"model_test.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4318520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_structure_format(text):\n",
    "    \"\"\"Convierte estructuras en texto a formato compatible\"\"\"\n",
    "    parts = text.split()\n",
    "    return ' '.join(f'<{p}>' for p in parts) if not text.startswith('<') else text\n",
    "\n",
    "def safe_structure_transform(text):\n",
    "    \"\"\"Transforma estructuras manejando casos desconocidos\"\"\"\n",
    "    formatted = convert_structure_format(text)\n",
    "    try:\n",
    "        return structure_encoder.transform([formatted])[0]\n",
    "    except ValueError:\n",
    "        default = '<verse> <chorus>'\n",
    "        print(f\"Estructura '{text}' no encontrada. Usando default: {default}\")\n",
    "        return structure_encoder.transform([default])[0]\n",
    "    \n",
    "def generate_chords(genre, structure, start_seq=\"<intro>\", max_len=32, temperature=0.8):\n",
    "    model.eval()\n",
    "    \n",
    "    # 1. Preprocesamiento seguro de inputs\n",
    "    genre_id = genre_encoder.transform([genre])[0]\n",
    "    structure_id = safe_structure_transform(structure)  # ¡Usamos la nueva función!\n",
    "    \n",
    "    # 2. Convertir secuencia inicial a índices\n",
    "    input_seq = [chord_to_idx.get(s, chord_to_idx['<unk>']) for s in start_seq.split()]\n",
    "    \n",
    "    # 3. Preparar tensores\n",
    "    input_tensor = torch.tensor([input_seq], dtype=torch.long).to(device)\n",
    "    genre_tensor = torch.tensor([genre_id], dtype=torch.long).to(device)\n",
    "    structure_tensor = torch.tensor([structure_id], dtype=torch.long).to(device)\n",
    "    \n",
    "    # 4. Generación\n",
    "    generated = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_len):\n",
    "            output = model(input_tensor, genre_tensor, structure_tensor)\n",
    "            probs = torch.softmax(output[0, -1] / temperature, dim=-1)\n",
    "            next_idx = torch.multinomial(probs, 1).item()\n",
    "            next_chord = idx_to_chord[next_idx]\n",
    "            \n",
    "            generated.append(next_chord)\n",
    "            input_tensor = torch.cat([\n",
    "                input_tensor, \n",
    "                torch.tensor([[next_idx]], device=device)\n",
    "            ], dim=1)\n",
    "            \n",
    "            # Detener si se completa una estructura\n",
    "            if next_chord.startswith('<') and len(generated) > 5:\n",
    "                break\n",
    "    \n",
    "    # 5. Post-procesamiento\n",
    "    return ' '.join(generated)\n",
    "\n",
    "progresion = generate_chords(\n",
    "    genre=\"jazz\",\n",
    "    structure=\"intro verse verse chorus verse verse\",  # ¡Sin < >!\n",
    "    start_seq=\"C Am\",\n",
    "    temperature=0.2\n",
    ")\n",
    "print(progresion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex-basics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
