{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJHmRIZy4svX"
      },
      "source": [
        "# Building Agentic RAG Systems\n",
        "\n",
        "This notebook is part of the [Hugging Face Agents Course](https://www.hf.co/learn/agents-course), a free Course from beginner to expert, where you learn to build Agents.\n",
        "\n",
        "![Agents course share](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/share.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNHb_Xna4x_3"
      },
      "source": [
        "## Let's install the dependencies and login to our HF account to access the Inference API\n",
        "\n",
        "If you haven't installed `smolagents` yet, you can do so by running the following command:the dependencies and login to our HF account to access the Inference API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRWw2n4S4Y87"
      },
      "outputs": [],
      "source": [
        "!pip install smolagents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agkxF_blaYid"
      },
      "source": [
        "Let's also login to the Hugging Face Hub to have access to the Inference API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiFQS5wj4mXy"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toG-RqWX4sIx"
      },
      "source": [
        "## Basic Retrieval with DuckDuckGo\n",
        "\n",
        "Let's build a simple agent that can search the web using DuckDuckGo. This agent will retrieve information and synthesize responses to answer queries. With Agentic RAG, Alfred's agent can:\n",
        "\n",
        "* Search for latest superhero party trends\n",
        "* Refine results to include luxury elements\n",
        "* Synthesize information into a complete plan\n",
        "\n",
        "Here's how Alfred's agent can achieve this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DPklsecm4sQA",
        "outputId": "cd092c8b-4ab9-4ba6-e83e-30b0f21cbaf6"
      },
      "outputs": [],
      "source": [
        "from smolagents import CodeAgent, DuckDuckGoSearchTool, HfApiModel\n",
        "\n",
        "# Initialize the search tool\n",
        "search_tool = DuckDuckGoSearchTool()\n",
        "\n",
        "# Initialize the model\n",
        "model = HfApiModel()\n",
        "\n",
        "agent = CodeAgent(\n",
        "    model = model,\n",
        "    tools=[search_tool]\n",
        ")\n",
        "\n",
        "# Example usage\n",
        "response = agent.run(\n",
        "    \"Search for luxury superhero-themed party ideas, including decorations, entertainment, and catering.\"\n",
        ")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHfIWdVWad77"
      },
      "source": [
        "The agent follows this process:\n",
        "\n",
        "1. **Analyzes the Request:** Alfred’s agent identifies the key elements of the query—luxury superhero-themed party planning, with focus on decor, entertainment, and catering.\n",
        "2. **Performs Retrieval:**  The agent leverages DuckDuckGo to search for the most relevant and up-to-date information, ensuring it aligns with Alfred’s refined preferences for a luxurious event.\n",
        "3. **Synthesizes Information:** After gathering the results, the agent processes them into a cohesive, actionable plan for Alfred, covering all aspects of the party.\n",
        "4. **Stores for Future Reference:** The agent stores the retrieved information for easy access when planning future events, optimizing efficiency in subsequent tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJWn_FDN47u3"
      },
      "source": [
        "## Custom Knowledge Base Tool\n",
        "\n",
        "For specialized tasks, a custom knowledge base can be invaluable. Let's create a tool that queries a vector database of technical documentation or specialized knowledge. Using semantic search, the agent can find the most relevant information for Alfred's needs.\n",
        "\n",
        "This approach combines predefined knowledge with semantic search to provide context-aware solutions for event planning. With specialized knowledge access, Alfred can perfect every detail of the party.\n",
        "\n",
        "Install the dependecies first and run!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcKM-MSR5Cw-"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-community rank_bm25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MRNJkqyR43F-",
        "outputId": "a267884e-427c-484a-af58-9af3098cb9a1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Find ideas for a luxury superhero-themed party, including entertainment, catering, and decoration options.</span>      <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ HfApiModel - Qwen/Qwen2.5-Coder-32B-Instruct ──────────────────────────────────────────────────────────────────╯</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
              "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
              "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mFind ideas for a luxury superhero-themed party, including entertainment, catering, and decoration options.\u001b[0m      \u001b[38;2;212;183;2m│\u001b[0m\n",
              "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
              "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m HfApiModel - Qwen/Qwen2.5-Coder-32B-Instruct \u001b[0m\u001b[38;2;212;183;2m─────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Error in generating model output:</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Server Error: Internal Server Error for url: </span>\n",
              "<span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://router.huggingface.co/hf-inference/models/Qwen/Qwen2.5-Coder-32B-Instruct/v1/chat/completions</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> (Request ID: </span>\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Root</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">-67f400f7-27923e8b56073ac5087e6e2f;</span><span style=\"color: #ffff00; text-decoration-color: #ffff00\">007e887a-0469-4f05-82f1-e342e75292a3</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">)</span>\n",
              "\n",
              "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Model too busy, unable to get response in less than </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">second</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">(s)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;31mError in generating model output:\u001b[0m\n",
              "\u001b[1;36m500\u001b[0m\u001b[1;31m Server Error: Internal Server Error for url: \u001b[0m\n",
              "\u001b[4;94mhttps://router.huggingface.co/hf-inference/models/Qwen/Qwen2.5-Coder-32B-Instruct/v1/chat/completions\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31mRequest ID: \u001b[0m\n",
              "\u001b[1;33mRoot\u001b[0m\u001b[1;31m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;31m-67f400f7-27923e8b56073ac5087e6e2f;\u001b[0m\u001b[93m007e887a-0469-4f05-82f1-e342e75292a3\u001b[0m\u001b[1;31m)\u001b[0m\n",
              "\n",
              "\u001b[1;31mModel too busy, unable to get response in less than \u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;35msecond\u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31ms\u001b[0m\u001b[1;31m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 64.34 seconds]</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2m[Step 1: Duration 64.34 seconds]\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "AgentGenerationError",
          "evalue": "Error in generating model output:\n500 Server Error: Internal Server Error for url: https://router.huggingface.co/hf-inference/models/Qwen/Qwen2.5-Coder-32B-Instruct/v1/chat/completions (Request ID: Root=1-67f400f7-27923e8b56073ac5087e6e2f;007e887a-0469-4f05-82f1-e342e75292a3)\n\nModel too busy, unable to get response in less than 60 second(s)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "File \u001b[0;32m~/Escritorio/UA/ex-basics/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m~/Escritorio/UA/ex-basics/lib/python3.12/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
            "\u001b[0;31mHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: https://router.huggingface.co/hf-inference/models/Qwen/Qwen2.5-Coder-32B-Instruct/v1/chat/completions",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
            "File \u001b[0;32m~/Escritorio/UA/ex-basics/lib/python3.12/site-packages/smolagents/agents.py:1186\u001b[0m, in \u001b[0;36mCodeAgent.step\u001b[0;34m(self, memory_step)\u001b[0m\n\u001b[1;32m   1185\u001b[0m additional_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrammar\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrammar} \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrammar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m-> 1186\u001b[0m chat_message: ChatMessage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m<end_code>\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mObservation:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCalling tools:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m memory_step\u001b[38;5;241m.\u001b[39mmodel_output_message \u001b[38;5;241m=\u001b[39m chat_message\n",
            "File \u001b[0;32m~/Escritorio/UA/ex-basics/lib/python3.12/site-packages/smolagents/models.py:994\u001b[0m, in \u001b[0;36mHfApiModel.__call__\u001b[0;34m(self, messages, stop_sequences, grammar, tools_to_call_from, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m completion_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_completion_kwargs(\n\u001b[1;32m    986\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m    987\u001b[0m     stop_sequences\u001b[38;5;241m=\u001b[39mstop_sequences,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    992\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    993\u001b[0m )\n\u001b[0;32m--> 994\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_input_token_count \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39musage\u001b[38;5;241m.\u001b[39mprompt_tokens\n",
            "File \u001b[0;32m~/Escritorio/UA/ex-basics/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:956\u001b[0m, in \u001b[0;36mInferenceClient.chat_completion\u001b[0;34m(self, messages, model, stream, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream_options, temperature, tool_choice, tool_prompt, tools, top_logprobs, top_p, extra_body)\u001b[0m\n\u001b[1;32m    949\u001b[0m request_parameters \u001b[38;5;241m=\u001b[39m provider_helper\u001b[38;5;241m.\u001b[39mprepare_request(\n\u001b[1;32m    950\u001b[0m     inputs\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m    951\u001b[0m     parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    954\u001b[0m     api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken,\n\u001b[1;32m    955\u001b[0m )\n\u001b[0;32m--> 956\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inner_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n",
            "File \u001b[0;32m~/Escritorio/UA/ex-basics/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:321\u001b[0m, in \u001b[0;36mInferenceClient._inner_post\u001b[0;34m(self, request_parameters, stream)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 321\u001b[0m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent\n",
            "File \u001b[0;32m~/Escritorio/UA/ex-basics/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:481\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[0;32m--> 481\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, \u001b[38;5;28mstr\u001b[39m(e), response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: https://router.huggingface.co/hf-inference/models/Qwen/Qwen2.5-Coder-32B-Instruct/v1/chat/completions (Request ID: Root=1-67f400f7-27923e8b56073ac5087e6e2f;007e887a-0469-4f05-82f1-e342e75292a3)\n\nModel too busy, unable to get response in less than 60 second(s)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mAgentGenerationError\u001b[0m                      Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 68\u001b[0m\n\u001b[1;32m     65\u001b[0m agent \u001b[38;5;241m=\u001b[39m CodeAgent(tools\u001b[38;5;241m=\u001b[39m[party_planning_retriever], model\u001b[38;5;241m=\u001b[39mHfApiModel())\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFind ideas for a luxury superhero-themed party, including entertainment, catering, and decoration options.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     70\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
            "File \u001b[0;32m~/Escritorio/UA/ex-basics/lib/python3.12/site-packages/smolagents/agents.py:323\u001b[0m, in \u001b[0;36mMultiStepAgent.run\u001b[0;34m(self, task, stream, reset, images, additional_args, max_steps)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(task\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask, max_steps\u001b[38;5;241m=\u001b[39mmax_steps, images\u001b[38;5;241m=\u001b[39mimages)\n\u001b[1;32m    322\u001b[0m \u001b[38;5;66;03m# Outputs are returned only at the end. We only look at the last step.\u001b[39;00m\n\u001b[0;32m--> 323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeque\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxlen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[0;32m~/Escritorio/UA/ex-basics/lib/python3.12/site-packages/smolagents/agents.py:337\u001b[0m, in \u001b[0;36mMultiStepAgent._run\u001b[0;34m(self, task, max_steps, images)\u001b[0m\n\u001b[1;32m    334\u001b[0m     final_answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_step(task, memory_step)\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m AgentGenerationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;66;03m# Agent generation errors are not caused by a Model error but an implementation error: so we should raise them and exit.\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m AgentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;66;03m# Other AgentError types are caused by the Model, so we should log them and iterate.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m     memory_step\u001b[38;5;241m.\u001b[39merror \u001b[38;5;241m=\u001b[39m e\n",
            "File \u001b[0;32m~/Escritorio/UA/ex-basics/lib/python3.12/site-packages/smolagents/agents.py:334\u001b[0m, in \u001b[0;36mMultiStepAgent._run\u001b[0;34m(self, task, max_steps, images)\u001b[0m\n\u001b[1;32m    332\u001b[0m memory_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_memory_step(step_start_time, images)\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m     final_answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m AgentGenerationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;66;03m# Agent generation errors are not caused by a Model error but an implementation error: so we should raise them and exit.\u001b[39;00m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
            "File \u001b[0;32m~/Escritorio/UA/ex-basics/lib/python3.12/site-packages/smolagents/agents.py:358\u001b[0m, in \u001b[0;36mMultiStepAgent._execute_step\u001b[0;34m(self, task, memory_step)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplanning_step(task, is_first_step\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_number \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m), step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_number)\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mlog_rule(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, level\u001b[38;5;241m=\u001b[39mLogLevel\u001b[38;5;241m.\u001b[39mINFO)\n\u001b[0;32m--> 358\u001b[0m final_answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemory_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_answer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_answer_checks:\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_final_answer(final_answer)\n",
            "File \u001b[0;32m~/Escritorio/UA/ex-basics/lib/python3.12/site-packages/smolagents/agents.py:1202\u001b[0m, in \u001b[0;36mCodeAgent.step\u001b[0;34m(self, memory_step)\u001b[0m\n\u001b[1;32m   1200\u001b[0m     memory_step\u001b[38;5;241m.\u001b[39mmodel_output \u001b[38;5;241m=\u001b[39m model_output\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AgentGenerationError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in generating model output:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mlog_markdown(\n\u001b[1;32m   1205\u001b[0m     content\u001b[38;5;241m=\u001b[39mmodel_output,\n\u001b[1;32m   1206\u001b[0m     title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput message of the LLM:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1207\u001b[0m     level\u001b[38;5;241m=\u001b[39mLogLevel\u001b[38;5;241m.\u001b[39mDEBUG,\n\u001b[1;32m   1208\u001b[0m )\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;66;03m# Parse\u001b[39;00m\n",
            "\u001b[0;31mAgentGenerationError\u001b[0m: Error in generating model output:\n500 Server Error: Internal Server Error for url: https://router.huggingface.co/hf-inference/models/Qwen/Qwen2.5-Coder-32B-Instruct/v1/chat/completions (Request ID: Root=1-67f400f7-27923e8b56073ac5087e6e2f;007e887a-0469-4f05-82f1-e342e75292a3)\n\nModel too busy, unable to get response in less than 60 second(s)"
          ]
        }
      ],
      "source": [
        "from langchain.docstore.document import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from smolagents import Tool\n",
        "from langchain_community.retrievers import BM25Retriever\n",
        "from smolagents import CodeAgent, HfApiModel\n",
        "\n",
        "class PartyPlanningRetrieverTool(Tool):\n",
        "    name = \"party_planning_retriever\"\n",
        "    description = \"Uses semantic search to retrieve relevant party planning ideas for Alfred’s superhero-themed party at Wayne Manor.\"\n",
        "    inputs = {\n",
        "        \"query\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The query to perform. This should be a query related to party planning or superhero themes.\",\n",
        "        }\n",
        "    }\n",
        "    output_type = \"string\"\n",
        "\n",
        "    def __init__(self, docs, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.retriever = BM25Retriever.from_documents(\n",
        "            docs, k=5  # Retrieve the top 5 documents\n",
        "        )\n",
        "\n",
        "    def forward(self, query: str) -> str:\n",
        "        assert isinstance(query, str), \"Your search query must be a string\"\n",
        "\n",
        "        docs = self.retriever.invoke(\n",
        "            query,\n",
        "        )\n",
        "        return \"\\nRetrieved ideas:\\n\" + \"\".join(\n",
        "            [\n",
        "                f\"\\n\\n===== Idea {str(i)} =====\\n\" + doc.page_content\n",
        "                for i, doc in enumerate(docs)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "# Simulate a knowledge base about party planning\n",
        "party_ideas = [\n",
        "    {\"text\": \"A superhero-themed masquerade ball with luxury decor, including gold accents and velvet curtains.\", \"source\": \"Party Ideas 1\"},\n",
        "    {\"text\": \"Hire a professional DJ who can play themed music for superheroes like Batman and Wonder Woman.\", \"source\": \"Entertainment Ideas\"},\n",
        "    {\"text\": \"For catering, serve dishes named after superheroes, like 'The Hulk's Green Smoothie' and 'Iron Man's Power Steak.'\", \"source\": \"Catering Ideas\"},\n",
        "    {\"text\": \"Decorate with iconic superhero logos and projections of Gotham and other superhero cities around the venue.\", \"source\": \"Decoration Ideas\"},\n",
        "    {\"text\": \"Interactive experiences with VR where guests can engage in superhero simulations or compete in themed games.\", \"source\": \"Entertainment Ideas\"}\n",
        "]\n",
        "\n",
        "source_docs = [\n",
        "    Document(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"]})\n",
        "    for doc in party_ideas\n",
        "]\n",
        "\n",
        "# Split the documents into smaller chunks for more efficient search\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=50,\n",
        "    add_start_index=True,\n",
        "    strip_whitespace=True,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
        ")\n",
        "docs_processed = text_splitter.split_documents(source_docs)\n",
        "\n",
        "# Create the retriever tool\n",
        "party_planning_retriever = PartyPlanningRetrieverTool(docs_processed)\n",
        "\n",
        "# Initialize the agent\n",
        "agent = CodeAgent(tools=[party_planning_retriever], model=HfApiModel())\n",
        "\n",
        "# Example usage\n",
        "response = agent.run(\n",
        "    \"Find ideas for a luxury superhero-themed party, including entertainment, catering, and decoration options.\"\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMENl0QaalSd"
      },
      "source": [
        "This enhanced agent can:\n",
        "1. First check the documentation for relevant information\n",
        "2. Combine insights from the knowledge base\n",
        "3. Maintain conversation context through memory"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ex-basics",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
